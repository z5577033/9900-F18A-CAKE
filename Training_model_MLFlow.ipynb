{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d526dd69-6efd-4f8e-8602-28cef9839690",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os,sys\n",
    "import mlflow, json, os, time\n",
    "from mlflow.tracking import MlflowClient\n",
    "import mlflow, time, json\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pyspark.sql import functions as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score, accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "071896be-deba-4966-aa58-13d01340ec54",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.widgets.text(\"only_node\", \"\")\n",
    "dbutils.widgets.text(\"mlflow_experiment\", \"/Workspace/9900-f18a-cake/classifier\")\n",
    "dbutils.widgets.text(\"id_col\",         \"sample_id\")\n",
    "\n",
    "ONLY_NODE        = dbutils.widgets.get(\"only_node\").strip()\n",
    "MLF_EXPERIMENT   = dbutils.widgets.get(\"mlflow_experiment\").strip()\n",
    "ID_COL           = dbutils.widgets.get(\"id_col\").strip()\n",
    "\n",
    "assert ONLY_NODE, \"Pass only_node\"\n",
    "print(f\"Training node: {ONLY_NODE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1aa7fa1a-210e-4ac2-b4be-5a574c11e537",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "os.environ.setdefault(\"OMP_NUM_THREADS\",\"1\")\n",
    "os.environ.setdefault(\"OPENBLAS_NUM_THREADS\",\"1\")\n",
    "os.environ.setdefault(\"MKL_NUM_THREADS\",\"1\")\n",
    "os.environ[\"RF_N_JOBS\"] = \"1\"\n",
    "os.environ[\"CV_N_JOBS\"] = \"1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c19e7bda-e72f-4322-bf36-7f76cc8ea712",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def use_catalog_and_schema_from_3part(name: str):\n",
    "    parts = name.split(\".\")\n",
    "    if len(parts) == 3:\n",
    "        spark.sql(f\"USE CATALOG {parts[0]}\")\n",
    "        spark.sql(f\"USE SCHEMA {parts[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "30fe41f8-05ed-4844-a909-def86ef76993",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def load_data_for_node(node_name: str):\n",
    "    # Resolve catalog/schema for both tables\n",
    "    use_catalog_and_schema_from_3part(FEATURES_TABLE)\n",
    "    use_catalog_and_schema_from_3part(LABELS_TABLE)\n",
    "\n",
    "    # 1) Read LONG features and pivot to WIDE: one row per biosample_id, one column per probe Name\n",
    "    feats_long = (\n",
    "        spark.table(FEATURES_TABLE)\n",
    "        .select(F.col(ID_COL).alias(\"biosample_id\"), \"Name\", F.col(\"MValue\").alias(\"m\"))\n",
    "        .dropna()\n",
    "    )\n",
    "\n",
    "    # Wide matrix; F.first to aggregate the single value per (biosample_id, Name)\n",
    "    feats_wide = (\n",
    "        feats_long.groupBy(\"biosample_id\")\n",
    "                  .pivot(\"Name\")\n",
    "                  .agg(F.first(\"m\"))\n",
    "    )\n",
    "\n",
    "    # 2) Read labels for THIS node and shape to (biosample_id, y)\n",
    "    labels_df = (\n",
    "        spark.table(LABELS_TABLE)\n",
    "        .where(F.col(\"node_id\") == F.lit(node_name))      # expects a node_id column\n",
    "        .select(F.col(ID_COL).alias(\"biosample_id\"), F.col(LABEL_COL).alias(\"y\"))\n",
    "        .dropna()\n",
    "        .dropDuplicates([\"biosample_id\"])\n",
    "    )\n",
    "\n",
    "    # 3) Join\n",
    "    df = feats_wide.join(labels_df, on=\"biosample_id\", how=\"inner\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f2946936-45ee-4d23-8a02-108716a03bd2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_node(node_name: str):\n",
    "    df = load_data_for_node(node_name)\n",
    "    n = df.count()\n",
    "    if n < 10:\n",
    "        raise ValueError(f\"Not enough samples for {node_name}: {n}\")\n",
    "\n",
    "    pdf = df.toPandas()\n",
    "    y    = pdf[\"y\"].values\n",
    "    X    = pdf.drop(columns=[ID_COL, \"y\"]).values\n",
    "    ids  = pdf[ID_COL].astype(str).values\n",
    "\n",
    "    # Stratified splits: 20% test, 20% of remaining as val\n",
    "    sss1 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1337)\n",
    "    (trv_idx, te_idx), = sss1.split(X, y)\n",
    "    X_trv, y_trv = X[trv_idx], y[trv_idx]\n",
    "    sss2 = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=1337)\n",
    "    (tr_idx, va_idx), = sss2.split(X_trv, y_trv)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=600, max_depth=None, n_jobs=1, random_state=1337\n",
    "    )\n",
    "\n",
    "    t0 = time.time()\n",
    "    model.fit(X_trv[tr_idx], y_trv[tr_idx])\n",
    "    train_sec = time.time() - t0\n",
    "\n",
    "    # Eval\n",
    "    def eval_split(Xs, ys):\n",
    "        yp = model.predict(Xs)\n",
    "        return {\n",
    "            \"acc\": accuracy_score(ys, yp),\n",
    "            \"f1_weighted\": f1_score(ys, yp, average=\"weighted\"),\n",
    "        }\n",
    "\n",
    "    m_val  = eval_split(X_trv[va_idx], y_trv[va_idx])\n",
    "    m_test = eval_split(X[te_idx],     y[te_idx])\n",
    "\n",
    "    # Detailed report as artifact\n",
    "    y_test_pred = model.predict(X[te_idx])\n",
    "    report = classification_report(y[te_idx], y_test_pred, output_dict=True)\n",
    "\n",
    "    return {\n",
    "        \"train_sec\": train_sec,\n",
    "        \"val\":  m_val,\n",
    "        \"test\": m_test,\n",
    "        \"report\": report,\n",
    "        \"model\": model,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1d2738e1-b536-4b11-99f8-cc9a5ba6fad9",
     "showTitle": false,
     "tableResultSettingsMap": {
      "1": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"databaseName\":345},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1762359751170}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 1
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "c = \"cb_prod\"\n",
    "s = \"`comp9300-9900-f18a-cake`\"\n",
    "\n",
    "print(\"Schemas in catalog:\", c)\n",
    "display(spark.sql(f\"SHOW SCHEMAS IN {c}\"))\n",
    "\n",
    "print(\"Candidates with 'label' in name:\")\n",
    "display(spark.sql(f\"SHOW TABLES IN {c}.{s} LIKE '*label*'\"))\n",
    "\n",
    "print(\"Other candidates (you can adjust patterns):\")\n",
    "display(spark.sql(f\"SHOW TABLES IN {c}.{s} LIKE '*class*'\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac03d63b-8d9f-486f-ab70-39b8732dad22",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "mlflow.set_experiment(MLF_EXPERIMENT)\n",
    "client = MlflowClient()\n",
    "\n",
    "with mlflow.start_run(run_name=f\"node={ONLY_NODE}\") as run:\n",
    "    run_id = run.info.run_id\n",
    "    if PARENT_ID:\n",
    "        client.set_tag(run_id, \"mlflow.parentRunId\", PARENT_ID)\n",
    "\n",
    "    mlflow.set_tag(\"node_id\", ONLY_NODE)\n",
    "    mlflow.set_tag(\"orchestrator\", \"fanout_notebook\")\n",
    "    mlflow.log_params({\n",
    "        \"rf_n_estimators\": 600,\n",
    "        \"splits\": \"80/20 test, then 80/20 train/val\",\n",
    "    })\n",
    "\n",
    "    out = train_node(ONLY_NODE)\n",
    "\n",
    "    mlflow.log_metric(\"train_sec\", out[\"train_sec\"])\n",
    "    for k,v in out[\"val\"].items():  mlflow.log_metric(f\"val_{k}\",  float(v))\n",
    "    for k,v in out[\"test\"].items(): mlflow.log_metric(f\"test_{k}\", float(v))\n",
    "\n",
    "    mlflow.log_dict(out[\"report\"], \"reports/test_classification_report.json\")\n",
    "\n",
    "    # Save model (optional)\n",
    "    try:\n",
    "        import mlflow.sklearn\n",
    "        mlflow.sklearn.log_model(out[\"model\"], artifact_path=\"model\")\n",
    "    except Exception as e:\n",
    "        mlflow.log_text(str(e), \"logs/model_log_model_error.txt\")\n",
    "\n",
    "    # Persist raw metrics for quick scraping, if you like\n",
    "    mlflow.log_dict({\n",
    "        \"node\": ONLY_NODE,\n",
    "        \"train_sec\": out[\"train_sec\"],\n",
    "        **{f\"val_{k}\": out[\"val\"][k]  for k in out[\"val\"]},\n",
    "        **{f\"test_{k}\": out[\"test\"][k] for k in out[\"test\"]},\n",
    "    }, \"metrics/summary.json\")\n",
    "\n",
    "print(\"Done:\", ONLY_NODE)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "dependencies": [
     "-r /Workspace/9900-f18a-cake/working_branch/requirements.txt"
    ],
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8514920842114675,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Training_model_MLFlow",
   "widgets": {
    "id_col": {
     "currentValue": "sample_id",
     "nuid": "7add1b25-7fc5-4cd5-9c6c-4b57714ab306",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "sample_id",
      "label": null,
      "name": "id_col",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "sample_id",
      "label": null,
      "name": "id_col",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "mlflow_experiment": {
     "currentValue": "/Workspace/9900-f18a-cake/classifier",
     "nuid": "6343be3b-3cba-45b9-9d6d-8f0401a0e6a5",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "/Workspace/9900-f18a-cake/classifier",
      "label": null,
      "name": "mlflow_experiment",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "/Workspace/9900-f18a-cake/classifier",
      "label": null,
      "name": "mlflow_experiment",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "only_node": {
     "currentValue": "Haematological malignancy",
     "nuid": "ead9020c-4584-4598-b26e-c6634e8f0fc6",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "only_node",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "only_node",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    },
    "parent_run_id": {
     "currentValue": "",
     "nuid": "5a046645-f0df-43d7-a85f-7727a80b3ddb",
     "typedWidgetInfo": {
      "autoCreated": false,
      "defaultValue": "",
      "label": null,
      "name": "parent_run_id",
      "options": {
       "widgetDisplayType": "Text",
       "validationRegex": null
      },
      "parameterDataType": "String"
     },
     "widgetInfo": {
      "widgetType": "text",
      "defaultValue": "",
      "label": null,
      "name": "parent_run_id",
      "options": {
       "widgetType": "text",
       "autoCreated": null,
       "validationRegex": null
      }
     }
    }
   }
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
