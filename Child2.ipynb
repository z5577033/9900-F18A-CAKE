{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "957b96a7-128b-47de-b3df-e6c20e458d6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os, json, sys\n",
    "import mlflow\n",
    "from pathlib import Path\n",
    "from mlflow.tracking import MlflowClient\n",
    "from pyspark.sql import functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a249224-7e7d-468a-8c57-e8e6083cfc9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"/Workspace/9900-f18a-cake\") \n",
    "sys.path.append(\"/Workspace/9900-f18a-cake/mt-method2/src\")\n",
    "sys.path.append(\"/Workspace/9900-f18a-cake/mt-method2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "527c6cb6-6278-47be-bb29-ee8f6e86eb9a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from mch.models.training import BatchModelTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1fd35493-6b76-4a9d-952a-9067377ec934",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def _set_env_from_plan(plan: dict):\n",
    "    # Minimal env config used by the trainer code\n",
    "    # Feature prefilter knobs\n",
    "    os.environ[\"MCH_PREFILTER_TOPK\"]      = str(plan.get(\"prefilter_topk\", 200))\n",
    "    os.environ[\"MCH_PREFILTER_SCAN_MAX\"]  = str(plan.get(\"prefilter_scan_max\", 20000))\n",
    "    os.environ[\"MCH_PREFILTER_CHUNK_SIZE\"]= str(plan.get(\"prefilter_chunk_size\", 5000))\n",
    "\n",
    "    # Disable/enable Differential Methylation step (1 disables)\n",
    "    os.environ[\"MCH_DISABLE_DM\"] = \"1\" if plan.get(\"disable_dm\", True) else \"0\"\n",
    "\n",
    "    # Limit nodes (train a single tree node)\n",
    "    only_node = plan.get(\"only_node\")\n",
    "    if only_node:\n",
    "        os.environ[\"MCH_ONLY_NODE\"] = str(only_node)\n",
    "    else:\n",
    "        os.environ.pop(\"MCH_ONLY_NODE\", None)\n",
    "\n",
    "    # Parallelism hints the trainer reads\n",
    "    os.environ[\"RF_N_JOBS\"] = str(plan.get(\"rf_n_jobs\", 1))\n",
    "    os.environ[\"CV_N_JOBS\"] = str(plan.get(\"cv_n_jobs\", 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "13e39e59-9d62-4266-8221-f47ce1e016f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def run_child(plan: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Run one training job driven by `plan`.\n",
    "    Returns a result dict (ok/metrics/etc.) that the parent will collect.\n",
    "    \"\"\"\n",
    "    start_ts = time.time()\n",
    "    node_id  = plan.get(\"node_id\", \"UNKNOWN\")\n",
    "    exp_path = plan.get(\"mlflow_experiment_path\", \"/Shared/methyl/experiments/classifier\")\n",
    "\n",
    "    # Make sure experiment exists (safe if it already does)\n",
    "    mlflow.set_experiment(exp_path)\n",
    "    exp = mlflow.get_experiment_by_name(exp_path)\n",
    "    if exp is None:\n",
    "        exp_id = mlflow.create_experiment(exp_path)\n",
    "    else:\n",
    "        exp_id = exp.experiment_id\n",
    "    mlflow.set_experiment(experiment_id=exp_id)\n",
    "\n",
    "    # Configure trainer via env vars\n",
    "    _set_env_from_plan(plan)\n",
    "\n",
    "    # Tags & params we want recorded\n",
    "    tags = {\n",
    "        \"orchestrator\": \"parent_notebook\",\n",
    "        \"node_id\": node_id,\n",
    "        \"only_node\": str(plan.get(\"only_node\")),\n",
    "        \"disable_dm\": str(plan.get(\"disable_dm\", True)),\n",
    "    }\n",
    "    params = {\n",
    "        \"prefilter_topk\":        plan.get(\"prefilter_topk\", 200),\n",
    "        \"prefilter_scan_max\":    plan.get(\"prefilter_scan_max\", 20000),\n",
    "        \"prefilter_chunk_size\":  plan.get(\"prefilter_chunk_size\", 5000),\n",
    "        \"rf_n_jobs\":             plan.get(\"rf_n_jobs\", 1),\n",
    "        \"cv_n_jobs\":             plan.get(\"cv_n_jobs\", 1),\n",
    "    }\n",
    "\n",
    "    result = {\n",
    "        \"ok\": False,\n",
    "        \"node_id\": node_id,\n",
    "        \"metrics\": {},\n",
    "        \"summary_path\": None,\n",
    "        \"error\": None,\n",
    "        \"trace\": None,\n",
    "        \"t_sec\": None,\n",
    "    }\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"node={node_id}\") as run:\n",
    "        # record basic config in MLflow\n",
    "        mlflow.set_tags(tags)\n",
    "        mlflow.log_params(params)\n",
    "\n",
    "        try:\n",
    "            # Instantiate & train (driven by env set above)\n",
    "            trainer = BatchModelTrainer()\n",
    "            stats = trainer.train_all_models(save_dir=None, raise_on_error=False)\n",
    "\n",
    "            # If we limited to a single node, pull that node's metrics if present\n",
    "            only_node = plan.get(\"only_node\")\n",
    "            node_key = only_node if only_node else node_id\n",
    "            node_stats = stats.get(node_key, {})\n",
    "\n",
    "            # Log a JSON summary artifact\n",
    "            out_dir = Path(\"/dbfs/tmp/mt_method2_child\")\n",
    "            out_dir.mkdir(parents=True, exist_ok=True)\n",
    "            summary_file = out_dir / f\"{node_id}_summary.json\"\n",
    "            with open(summary_file, \"w\", encoding=\"utf-8\") as f:\n",
    "                json.dump({\"node\": node_key, \"stats\": node_stats, \"all\": stats}, f, indent=2)\n",
    "            mlflow.log_artifact(str(summary_file), artifact_path=\"child_summaries\")\n",
    "\n",
    "            # Also log top-level metrics (if we have them)\n",
    "            metrics = node_stats.get(\"metrics\", {})\n",
    "            for k, v in metrics.items():\n",
    "                if isinstance(v, (int, float)):\n",
    "                    mlflow.log_metric(k, float(v))\n",
    "\n",
    "            result[\"ok\"] = True\n",
    "            result[\"metrics\"] = metrics\n",
    "            result[\"summary_path\"] = str(summary_file)\n",
    "\n",
    "        except Exception as e:\n",
    "            result[\"error\"] = f\"{type(e).__name__}: {e}\"\n",
    "            result[\"trace\"] = traceback.format_exc()\n",
    "\n",
    "        finally:\n",
    "            result[\"t_sec\"] = round(time.time() - start_ts, 3)\n",
    "\n",
    "    return result"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Child2",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
