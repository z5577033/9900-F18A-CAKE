{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "90759e9c-b1b5-4ce7-b4c9-d99f9b7ce59c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "import polars as pl\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(r\"/Workspace/9900-f18a-cake/working_branch/src\")\n",
    "\n",
    "\n",
    "CSV_PATH = \"/Volumes/cb_prod/comp9300-9900-f18a-cake/9900-f18a-cake/data/mvalue_outputs_masked/MValue_concat.csv\"\n",
    "# CSV_PATH = \"/Volumes/cb_prod/comp9300-9900-f18a-cake/9900-f18a-cake/data/mvalue_outputs_masked_subset_leukaemia_subsampled/MValue_polaris_pivot_0.csv\"\n",
    "# CSV_PATH = \"/Volumes/cb_prod/comp9300-9900-f18b-cake/9900-f18b-cake/data/mvalue_outputs_masked/MValue_concat.csv\"\n",
    "JOBLIB_PATH = \"/Workspace/9900-f18a-cake/working_branch/data/freeze0525/diseaseTree_mapped.joblib\"\n",
    "OUTPUT_PATH = \"/Workspace/9900-f18a-cake/working_branch/data/freeze0525/biosample_alignment.csv\"\n",
    "\n",
    "ID_PATTERN = re.compile(r\".*_T_.*_M$\")  # 2J0D2U4J_T_XJAFP6HU_M\n",
    "\n",
    "try:\n",
    "    df_csv = pl.read_csv(CSV_PATH, columns=[\"biosample_id\"], ignore_errors=True)\n",
    "except Exception:\n",
    "    df_csv = pl.read_csv(CSV_PATH, ignore_errors=True)\n",
    "    if \"biosample_id\" not in df_csv.columns:\n",
    "        for c in df_csv.columns:\n",
    "            if c.lower() == \"biosample_id\":\n",
    "                df_csv = df_csv.rename({c: \"biosample_id\"})\n",
    "                break\n",
    "\n",
    "csv_ids = [str(x).strip() for x in df_csv[\"biosample_id\"].to_list() if x and str(x).strip()]\n",
    "print(f\"read csv done {len(csv_ids)} samples total\")\n",
    "print(csv_ids[:10])\n",
    "\n",
    "def deep_scan_ids(obj, ids: set, _depth=0, _maxdepth=8):\n",
    "    if obj is None or _depth > _maxdepth:\n",
    "        return\n",
    "    if isinstance(obj, str):\n",
    "        if ID_PATTERN.match(obj):\n",
    "            ids.add(obj)\n",
    "        return\n",
    "    if isinstance(obj, (list, tuple, set)):\n",
    "        for it in obj:\n",
    "            deep_scan_ids(it, ids, _depth + 1)\n",
    "        return\n",
    "    if isinstance(obj, dict):\n",
    "        for k, v in obj.items():\n",
    "            if isinstance(k, str) and ID_PATTERN.match(k):\n",
    "                ids.add(k)\n",
    "            deep_scan_ids(v, ids, _depth + 1)\n",
    "        return\n",
    "    if hasattr(obj, \"__dict__\"):\n",
    "        deep_scan_ids(vars(obj), ids, _depth + 1)\n",
    "\n",
    "obj = joblib.load(JOBLIB_PATH)\n",
    "joblib_ids = set()\n",
    "deep_scan_ids(obj, joblib_ids)\n",
    "joblib_ids = sorted(joblib_ids)\n",
    "\n",
    "from pprint import pprint\n",
    "\n",
    "print(type(obj))\n",
    "pprint(obj)\n",
    "\n",
    "print(f\"read Joblib done {len(joblib_ids)} samples total\")\n",
    "print(joblib_ids[:10])\n",
    "\n",
    "\n",
    "csv_set = set(csv_ids)\n",
    "joblib_set = set(joblib_ids)\n",
    "\n",
    "intersection = csv_set & joblib_set\n",
    "csv_only = csv_set - joblib_set\n",
    "joblib_only = joblib_set - csv_set\n",
    "\n",
    "print(f\"ðŸ”¹ CSV count: {len(csv_set)}\")\n",
    "print(f\"ðŸ”¹ Joblib count: {len(joblib_set)}\")\n",
    "print(f\"ðŸ”¹ joint count: {len(intersection)}\")\n",
    "print(f\"ðŸ”¹ CSV only: {len(csv_only)}\")\n",
    "print(f\"ðŸ”¹ Joblib only: {len(joblib_only)}\")\n",
    "\n",
    "\n",
    "\n",
    "plt.figure(figsize=(6,5))\n",
    "plt.bar([\"CSV only\", \"Joblib only\", \"Align\"], \n",
    "        [len(csv_only), len(joblib_only), len(intersection)],\n",
    "        color=[\"#66c2a5\", \"#fc8d62\", \"#8da0cb\"])\n",
    "plt.ylabel(\"Sample cnt\")\n",
    "plt.title(\"Biosample ID joint\")\n",
    "for i, v in enumerate([len(csv_only), len(joblib_only), len(intersection)]):\n",
    "    plt.text(i, v + 2, str(v), ha=\"center\", fontweight=\"bold\")\n",
    "plt.show()\n",
    "\n",
    "alignment_df = pd.DataFrame({\n",
    "    \"biosample_id_csv\": list(csv_set),\n",
    "    \"in_joblib\": [x in joblib_set for x in csv_set]\n",
    "})\n",
    "\n",
    "Path(OUTPUT_PATH).parent.mkdir(parents=True, exist_ok=True)\n",
    "alignment_df.to_csv(OUTPUT_PATH, index=False)\n",
    "print(f\"Align output: {OUTPUT_PATH}\")\n",
    "alignment_df.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0d67b4f3-d718-4453-8a1f-4c053c3db0b6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pprint import pprint\n",
    "import joblib\n",
    "import polars as pl\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import sys\n",
    "sys.path.append(r\"/Workspace/9900-f18a-cake/working_branch/src\")\n",
    "\n",
    "obj = joblib.load(JOBLIB_PATH)\n",
    "\n",
    "print(type(obj))\n",
    "pprint(obj)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "data_check",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
