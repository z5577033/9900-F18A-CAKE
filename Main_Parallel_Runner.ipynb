{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "418d4904-bdd6-4362-8a7a-9afe05b099ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import joblib\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "import time\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Set your source code path\n",
    "# (This MUST be the same as in Training_model.ipynb)\n",
    "sys.path.append(r\"/Workspace/9900-f18a-cake/working_branch/src\")\n",
    "\n",
    "# 2. Define the path to the \"Worker\" Notebook\n",
    "# (We assume it's in the same folder)\n",
    "WORKER_NOTEBOOK_PATH = \"./Training_model\"\n",
    "\n",
    "print(\"Environment setup complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0c3383b0-bc71-4a92-acd3-3aa25e1d124c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "JOBLIB_PATH = \"/Workspace/9900-f18a-cake/working_branch/data/freeze0525/diseaseTree_mapped.joblib\"\n",
    "\n",
    "try:\n",
    "    tree_object = joblib.load(JOBLIB_PATH)\n",
    "    print(\"DiseaseTree node list loaded successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to load DiseaseTree: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6bf8c98e-8aa6-422f-b4ff-c66a5795e2e9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_nodes_to_train(tree):\n",
    "    \"\"\"\n",
    "    Recursively traverses the DiseaseTree and returns a list of all node names to be trained.\n",
    "    \"\"\"\n",
    "    all_nodes = []\n",
    "    \n",
    "    def traverse(node):\n",
    "        # Logic: Train a model for any non-root node that has samples\n",
    "        # (You can adjust this logic as needed)\n",
    "        if node.name != 'ZERO2' and hasattr(node, 'samples') and len(node.samples) > 0:\n",
    "             all_nodes.append(node.name)\n",
    "        \n",
    "        # Recurse into children\n",
    "        if hasattr(node, 'children'):\n",
    "            for child in node.children:\n",
    "                traverse(child)\n",
    "\n",
    "    traverse(tree)\n",
    "    unique_nodes = list(set(all_nodes))\n",
    "    print(f\"Extracted {len(unique_nodes)} unique nodes from DiseaseTree.\")\n",
    "    return unique_nodes\n",
    "\n",
    "# Run the function\n",
    "nodes_to_train = get_nodes_to_train(tree_object)\n",
    "print(f\"Node list (first 10): {nodes_to_train[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3273ed0e-19d5-4277-9025-6824c5e7e685",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def train_node_parallel(node_name):\n",
    "    \"\"\"\n",
    "    This is the task each parallel thread will execute.\n",
    "    It calls the 'Training_model' notebook to train a single node.\n",
    "    \"\"\"\n",
    "    print(f\"➡️  [START] Node: {node_name}\")\n",
    "    \n",
    "    # 1. Parameters to pass to the 'Training_model' notebook\n",
    "    params = {\n",
    "      \"only_node\": node_name \n",
    "    }\n",
    "    \n",
    "    # 2. Timeout (e.g., 2 hours)\n",
    "    timeout_seconds = 7200 \n",
    "    \n",
    "    try:\n",
    "        # 3. Execute!\n",
    "        # This starts the WORKER_NOTEBOOK_PATH in a new job\n",
    "        # and waits for it to return or time out\n",
    "        result_json = dbutils.notebook.run(WORKER_NOTEBOOK_PATH, timeout_seconds, params)\n",
    "        \n",
    "        print(f\"✅  [SUCCESS] Node: {node_name}.\")\n",
    "        return (node_name, \"Success\", result_json)\n",
    "    \n",
    "    except Exception as e:\n",
    "        # 4. Capture any failed jobs\n",
    "        print(f\"❌  [FAILED] Node: {node_name}. Error: {e}\")\n",
    "        return (node_name, \"Failed\", str(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "725f5245-14d9-4b6a-87a1-ae788d441f37",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# --- [CONFIGURE YOUR RUN] ---\n",
    "\n",
    "# 1. Set your desired maximum number of parallel runs\n",
    "MAX_PARALLEL_RUNS = 10\n",
    "\n",
    "# 2. (For Testing)\n",
    "#    Run only the first 5 nodes to test pipeline\n",
    "nodes_to_run = nodes_to_train[:5] \n",
    "\n",
    "# 3. (For Production)\n",
    "#    Once testing is successful, uncomment the line below to run all nodes\n",
    "# nodes_to_run = nodes_to_train\n",
    "\n",
    "# --------------------------\n",
    "\n",
    "print(f\"--- Starting parallel training for {len(nodes_to_run)} nodes, max parallelism: {MAX_PARALLEL_RUNS} ---\")\n",
    "start_time = time.time()\n",
    "all_results = [] # To store (node_name, status, json_output)\n",
    "\n",
    "# Use ThreadPoolExecutor to manage the parallel runs\n",
    "with ThreadPoolExecutor(max_workers=MAX_PARALLEL_RUNS) as executor:\n",
    "    # Submit all jobs\n",
    "    futures = [executor.submit(train_node_parallel, node) for node in nodes_to_run]\n",
    "    \n",
    "    # Collect results as they complete\n",
    "    for future in futures:\n",
    "        all_results.append(future.result())\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"\\n--- [ALL JOBS COMPLETE] ---\")\n",
    "print(f\"Total time taken: {end_time - start_time:.2f} seconds ( {(end_time - start_time)/60:.2f} minutes )\")\n",
    "\n",
    "\n",
    "# --- [SUMMARY REPORT] ---\n",
    "print(\"\\n--- Summary Report ---\")\n",
    "success_count = 0\n",
    "failed_nodes = []\n",
    "all_stats_dfs = [] # To store all successful results\n",
    "\n",
    "for (node_name, status, result_data) in all_results:\n",
    "    if status == \"Success\":\n",
    "        success_count += 1\n",
    "        try:\n",
    "            # Try to convert the returned JSON back into a DataFrame\n",
    "            node_stats_df = pd.read_json(result_data, orient='records')\n",
    "            node_stats_df['node'] = node_name # Add a column to identify the node\n",
    "            all_stats_dfs.append(node_stats_df)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not parse results from node {node_name}: {e}\")\n",
    "    else:\n",
    "        failed_nodes.append(node_name)\n",
    "\n",
    "print(f\"Successful: {success_count} / {len(nodes_to_run)}\")\n",
    "print(f\"Failed: {len(failed_nodes)} / {len(nodes_to_run)}\")\n",
    "if failed_nodes:\n",
    "    print(f\"List of failed nodes: {failed_nodes}\")\n",
    "\n",
    "# 4. Combine all successful results and display them\n",
    "if all_stats_dfs:\n",
    "    final_stats_summary = pd.concat(all_stats_dfs, ignore_index=True)\n",
    "    print(\"\\n--- [All Model Performance Metrics] ---\")\n",
    "    display(final_stats_summary)"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Main_Parallel_Runner",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
